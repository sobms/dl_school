{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of [homework,prodv]knn.ipynb","provenance":[{"file_id":"1Ey36Ii5nwDoQKDIK9WfVEX5CFeN5pDaE","timestamp":1584833952601}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"pgFYFftQKxY5"},"source":["<img src=\"https://s8.hostingkartinok.com/uploads/images/2018/08/308b49fcfbc619d629fe4604bceb67ac.jpg\" width=500, height=450>\n","<h3 style=\"text-align: center;\"><b>Физтех-Школа Прикладной математики и информатики (ФПМИ) МФТИ</b></h3>"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"3dvlDL37LaSp"},"source":["---"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"v4RCHGZULaWz"},"source":["На основе [курса по Машинному Обучению ФИВТ МФТИ](https://github.com/ml-mipt/ml-mipt) и [Открытого курса по Машинному Обучению](https://habr.com/ru/company/ods/blog/322626/)."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"F2acNQu1L94J"},"source":["---"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Twe_cnn5KxY6"},"source":["<h2 style=\"text-align: center;\"><b>K Nearest Neighbors (KNN)</b></h2>"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"YD0NXyUYKxY7"},"source":["Метод ближайших соседей (k Nearest Neighbors, или kNN) — очень популярный метод классификации, также иногда используемый в задачах регрессии. Это один из самых понятных подходов к классификации. На уровне интуиции суть метода такова: посмотри на соседей, какие преобладают, таков и ты. Формально основой метода является гипотеза компактности: если метрика расстояния между примерами введена достаточно удачно, то схожие примеры гораздо чаще лежат в одном классе, чем в разных. "]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"CTa2jNZkKxY8"},"source":["<img src='https://hsto.org/web/68d/a45/6f0/68da456f00f8434e87628dbe7e3f54a7.png' width=600>"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"5H7wPU0IKxY-"},"source":["\n","Для классификации каждого из объектов тестовой выборки необходимо последовательно выполнить следующие операции:\n","\n","* Вычислить расстояние до каждого из объектов обучающей выборки\n","* Отобрать объектов обучающей выборки, расстояние до которых минимально\n","* Класс классифицируемого объекта — это класс, наиболее часто встречающийся среди $k$ ближайших соседей"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"T2docs4225pb"},"source":["Будем работать с подвыборкой из [данных о типе лесного покрытия из репозитория UCI](http://archive.ics.uci.edu/ml/datasets/Covertype). Доступно 7 различных классов. Каждый объект описывается 54 признаками, 40 из которых являются бинарными. Описание данных доступно по ссылке, а так же в файле `covtype.info.txt`."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"AcjJQX3wKxZA"},"source":["### Обработка данных"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Ozcx5mVOKxZB","colab":{}},"source":["import pandas as pd\n","import numpy as np"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Ry4bMKaUjHJj"},"source":["ССылка на датасет (лежит в в папке): https://drive.google.com/open?id=1-Z4NlDy11BzSwW13k8EgodRis0uRy1K6"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"rvPrVRvK25pc","outputId":"aa4efbf7-481a-4619-f018-70939dcf4a49","executionInfo":{"status":"ok","timestamp":1584837064406,"user_tz":-180,"elapsed":653,"user":{"displayName":"Михаил Соболев","photoUrl":"","userId":"12877021176396650084"}},"colab":{"base_uri":"https://localhost:8080/","height":217}},"source":["all_data = pd.read_csv('/content/forest_dataset.csv',)\n","all_data.head()"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>10</th>\n","      <th>11</th>\n","      <th>12</th>\n","      <th>13</th>\n","      <th>14</th>\n","      <th>15</th>\n","      <th>16</th>\n","      <th>17</th>\n","      <th>18</th>\n","      <th>19</th>\n","      <th>20</th>\n","      <th>21</th>\n","      <th>22</th>\n","      <th>23</th>\n","      <th>24</th>\n","      <th>25</th>\n","      <th>26</th>\n","      <th>27</th>\n","      <th>28</th>\n","      <th>29</th>\n","      <th>30</th>\n","      <th>31</th>\n","      <th>32</th>\n","      <th>33</th>\n","      <th>34</th>\n","      <th>35</th>\n","      <th>36</th>\n","      <th>37</th>\n","      <th>38</th>\n","      <th>39</th>\n","      <th>40</th>\n","      <th>41</th>\n","      <th>42</th>\n","      <th>43</th>\n","      <th>44</th>\n","      <th>45</th>\n","      <th>46</th>\n","      <th>47</th>\n","      <th>48</th>\n","      <th>49</th>\n","      <th>50</th>\n","      <th>51</th>\n","      <th>52</th>\n","      <th>53</th>\n","      <th>54</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2683</td>\n","      <td>333</td>\n","      <td>35</td>\n","      <td>30</td>\n","      <td>26</td>\n","      <td>2743</td>\n","      <td>121</td>\n","      <td>173</td>\n","      <td>179</td>\n","      <td>6572</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2915</td>\n","      <td>90</td>\n","      <td>8</td>\n","      <td>216</td>\n","      <td>11</td>\n","      <td>4433</td>\n","      <td>232</td>\n","      <td>228</td>\n","      <td>129</td>\n","      <td>4019</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2941</td>\n","      <td>162</td>\n","      <td>7</td>\n","      <td>698</td>\n","      <td>76</td>\n","      <td>2783</td>\n","      <td>227</td>\n","      <td>242</td>\n","      <td>148</td>\n","      <td>1784</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3096</td>\n","      <td>60</td>\n","      <td>17</td>\n","      <td>170</td>\n","      <td>3</td>\n","      <td>3303</td>\n","      <td>231</td>\n","      <td>202</td>\n","      <td>99</td>\n","      <td>5370</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2999</td>\n","      <td>66</td>\n","      <td>8</td>\n","      <td>488</td>\n","      <td>37</td>\n","      <td>1532</td>\n","      <td>228</td>\n","      <td>225</td>\n","      <td>131</td>\n","      <td>2290</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      0    1   2    3   4     5    6    7  ...  47  48  49  50  51  52  53  54\n","0  2683  333  35   30  26  2743  121  173  ...   0   0   0   0   0   0   0   2\n","1  2915   90   8  216  11  4433  232  228  ...   0   0   0   0   0   0   0   1\n","2  2941  162   7  698  76  2783  227  242  ...   0   0   0   0   0   0   0   2\n","3  3096   60  17  170   3  3303  231  202  ...   0   0   0   0   0   0   0   1\n","4  2999   66   8  488  37  1532  228  225  ...   0   0   0   0   0   0   0   2\n","\n","[5 rows x 55 columns]"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"_o8yXBPSKxZI","outputId":"9012911f-1a12-4aa6-9fd1-485bdbd9982d","executionInfo":{"status":"ok","timestamp":1584837144679,"user_tz":-180,"elapsed":711,"user":{"displayName":"Михаил Соболев","photoUrl":"","userId":"12877021176396650084"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["all_data.shape"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(10000, 55)"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"itCWxHEY25pg"},"source":["Выделим значения метки класса в переменную `labels`, признаковые описания в переменную `feature_matrix`. Так как данные числовые и не имеют пропусков, переведем их в `numpy`-формат с помощью метода `.values`."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"f_YIUOuV25ph","colab":{}},"source":["labels = all_data[all_data.columns[-1]].values\n","feature_matrix = all_data[all_data.columns[:-1]].values"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FukXaH_r8PMQ","colab_type":"text"},"source":["### Пара слов о sklearn"]},{"cell_type":"markdown","metadata":{"id":"k5S_0Lfc8PMR","colab_type":"text"},"source":["**[sklearn](https://scikit-learn.org/stable/index.html)** -- удобная библиотека для знакомства с машинным обучением. В ней реализованны большинство стандартных алгоритмов для построения моделей и работ с выборками. У неё есть подробная документация на английском, с которой вам придётся поработать."]},{"cell_type":"markdown","metadata":{"id":"VhVDEG538PMS","colab_type":"text"},"source":["`sklearn` предпологает, что ваши выборки имеют вид пар $(X, y)$, где $X$ -- матрица признаков, $y$ -- вектор истинных значений целевой переменной, или просто $X$, если целевые переменные неизвестны."]},{"cell_type":"markdown","metadata":{"id":"QJZQulsp8PMT","colab_type":"text"},"source":["Познакомимся с вспомогательной функцией \n","[train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html).\n","С её помощью можно разбить выборку на тестовую и обучающую части."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Q030jzyY25pl","colab":{}},"source":["from sklearn.model_selection import train_test_split"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UkeB47mX8PMY","colab_type":"text"},"source":["Вернёмся к датасету. Сейчас будем работать со всеми 7 типами покрытия (данные уже находятся в переменных `feature_matrix` и `labels`, если Вы их не переопределили). Разделим выборку на обучающую и тестовую с помощью метода `train_test_split`."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"YJN0jFARKxZX","colab":{}},"source":["train_feature_matrix, test_feature_matrix, train_labels, test_labels = train_test_split(\n","    feature_matrix, labels, test_size=0.2, random_state=42)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"odC1c7X48PMb","colab_type":"text"},"source":["Параметр `test_size` контролирует, какая часть выборки будет тестовой. Более подробно о нём можно прочитать в [документации](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)."]},{"cell_type":"markdown","metadata":{"id":"z3fGvPqG8PMc","colab_type":"text"},"source":["Основные объекты `sklearn` -- так называемые `estimators`, что можно перевести как *оценщики*, но не стоит, так как по сути это *модели*. Они делятся на **классификаторы** и **регрессоры**.\n","\n","В качестве примера модели можно привести классификаторы\n","[метод ближайших соседей](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html) и \n","[логистическую регрессию](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html). Что такое логистическая регрессия и как она работает сейчас не важно."]},{"cell_type":"markdown","metadata":{"id":"IuX8Rc7c8PMd","colab_type":"text"},"source":["У всех моделей в `sklearn` обязательно должно быть хотя бы 2 метода (подробнее о методах и классах в python будет в следующих занятиях) -- `fit` и `predict`."]},{"cell_type":"markdown","metadata":{"id":"ZYokUkxO8PMe","colab_type":"text"},"source":["Метод `fit(X, y)` отвечает за обучение модели и принимает на вход обучающую выборку в виде *матрицы признаков* $X$ и *вектора ответов* $y$.\n","\n","У обученной после `fit` модели теперь можно вызывать метод `predict(X)`, который вернёт предсказания этой модели на всех объектах из матрицы $X$ в виде вектора.\n","\n","Вызывать `fit` у одной и той же модели можно несколько раз, каждый раз она будет обучаться заново на переданном наборе данных.\n","\n","Ещё у моделей есть *гиперпараметры*, которые обычно задаются при создании модели.\n","\n","Рассмотрим всё это на примере логистической регрессии."]},{"cell_type":"code","metadata":{"id":"ew0Ji_2D8PMe","colab_type":"code","colab":{}},"source":["from sklearn.linear_model import LogisticRegression"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"c9KcMHXr8PMh","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":178},"outputId":"38c1e7c5-a433-453e-d82c-4293664abbf9","executionInfo":{"status":"ok","timestamp":1584838822014,"user_tz":-180,"elapsed":1883,"user":{"displayName":"Михаил Соболев","photoUrl":"","userId":"12877021176396650084"}}},"source":["# создание модели с указанием гиперпараметра C\n","clf = LogisticRegression(C=1)\n","# обучение модели\n","clf.fit(train_feature_matrix, train_labels)\n","# предсказание на тестовой выборке\n","y_pred = clf.predict(test_feature_matrix)"],"execution_count":21,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"h3gjg3pm8PMm","colab_type":"text"},"source":["Теперь хотелось бы измерить качество нашей модели. Для этого можно использовать метод `score(X, y)`, который посчитает какую-то функцию ошибки на выборке $X, y$, но какую конкретно уже зависит от модели. Также можно использовать одну из функций модуля `metrics`, например [accuracy_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html), которая, как понятно из названия, вычислит нам точность предсказаний."]},{"cell_type":"code","metadata":{"id":"J2Ej1Lni8PMn","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"1a0a5797-a186-4e5f-9526-793f99904efa","executionInfo":{"status":"ok","timestamp":1584838891449,"user_tz":-180,"elapsed":657,"user":{"displayName":"Михаил Соболев","photoUrl":"","userId":"12877021176396650084"}}},"source":["from sklearn.metrics import accuracy_score\n","\n","accuracy_score(test_labels, y_pred)"],"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.6075"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"markdown","metadata":{"id":"malIDW_P8PMp","colab_type":"text"},"source":["Наконец, последним, о чём хотелось бы упомянуть, будет перебор гиперпараметров по сетке. Так как у моделей есть много гиперпараметров, которые можно изменять, и от этих гиперпараметров существенно зависит качество модели, хотелось бы найти наилучшие в этом смысле параметры. Самый простой способ это сделать -- просто перебрать все возможные варианты в разумных пределах.\n","\n","Сделать это можно с помощью класса [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html), который осуществляет поиск (search) по сетке (grid) и вычисляет качество модели с помощью кросс-валидации (CV).\n","\n","У логистической регрессии, например, можно поменять параметры `C` и `penalty`. Сделаем это. Учтите, что поиск может занять долгое время. Смысл параметров смотрите в документации."]},{"cell_type":"code","metadata":{"id":"vq687Aoc8PMq","colab_type":"code","colab":{}},"source":["from sklearn.model_selection import GridSearchCV"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OVnqHBvK8PMs","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":90},"outputId":"d3936237-9cac-4c6d-db61-4ac0256cafc2","executionInfo":{"status":"ok","timestamp":1584839137553,"user_tz":-180,"elapsed":96274,"user":{"displayName":"Михаил Соболев","photoUrl":"","userId":"12877021176396650084"}}},"source":["# заново создадим модель, указав солвер\n","clf = LogisticRegression(solver='saga')\n","\n","# опишем сетку, по которой будем искать\n","param_grid = {\n","    'C': np.arange(1, 5), # также можно указать обычный массив, [1, 2, 3, 4]\n","    'penalty': ['l1', 'l2'],\n","}\n","\n","# создадим объект GridSearchCV\n","search = GridSearchCV(clf, param_grid, n_jobs=-1, cv=5, refit=True, scoring='accuracy')\n","\n","# запустим поиск\n","search.fit(feature_matrix, labels)\n","\n","# выведем наилучшие параметры\n","print(search.best_params_)"],"execution_count":25,"outputs":[{"output_type":"stream","text":["{'C': 4, 'penalty': 'l2'}\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  \"the coef_ did not converge\", ConvergenceWarning)\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"DnVTFcvZ8PMv","colab_type":"text"},"source":["В данном случае, поиск перебирает все возможные пары значений C и penalty из заданных множеств."]},{"cell_type":"code","metadata":{"id":"ArKINrE_8PMw","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"3691b5b0-822d-40a0-9bce-48acbfa7f090","executionInfo":{"status":"ok","timestamp":1584839157871,"user_tz":-180,"elapsed":752,"user":{"displayName":"Михаил Соболев","photoUrl":"","userId":"12877021176396650084"}}},"source":["accuracy_score(labels, search.best_estimator_.predict(feature_matrix))"],"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.6417"]},"metadata":{"tags":[]},"execution_count":26}]},{"cell_type":"markdown","metadata":{"id":"okzpKY_I8PMz","colab_type":"text"},"source":["Заметьте, что мы передаём в GridSearchCV всю выборку, а не только её обучающую часть. Это можно делать, так как поиск всё равно использует кроссвалидацию. Однако порой от выборки всё-же отделяют *валидационную* часть, так как гиперпараметры в процессе поиска могли переобучиться под выборку."]},{"cell_type":"markdown","metadata":{"id":"_mdJyxdo8PM1","colab_type":"text"},"source":["В заданиях вам предстоит повторить это для метода ближайших соседей."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"z8W__017KxZc"},"source":["### Обучение модели"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"02uT6CPYKxZe"},"source":["Качество классификации/регрессии методом ближайших соседей зависит от нескольких параметров:\n","\n","* число соседей `n_neighbors`\n","* метрика расстояния между объектами `metric`\n","* веса соседей (соседи тестового примера могут входить с разными весами, например, чем дальше пример, тем с меньшим коэффициентом учитывается его \"голос\") `weights`\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"BHVNCaJ325qD"},"source":["Обучите на датасете `KNeighborsClassifier` из `sklearn`."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"o4CMnnOY25qD","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"afa063d8-72b5-4b10-f68c-36e48efa15d4","executionInfo":{"status":"ok","timestamp":1584840599402,"user_tz":-180,"elapsed":885,"user":{"displayName":"Михаил Соболев","photoUrl":"","userId":"12877021176396650084"}}},"source":["from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.metrics import accuracy_score\n","\n","neig =  KNeighborsClassifier(n_neighbors=7)\n","neig.fit(train_feature_matrix,train_labels)\n","pred=neig.predict(test_feature_matrix)\n","neig.score(test_feature_matrix,test_labels,pred)"],"execution_count":31,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.7378481703986892"]},"metadata":{"tags":[]},"execution_count":31}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"r_2Mf8BiKxZk"},"source":["### Вопрос 1:\n","* Какое качество у вас получилось?"]},{"cell_type":"markdown","metadata":{"id":"QC1TqRiQ3PS2","colab_type":"text"},"source":["0.7378481703986892"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"uFTIaPdrKxZl"},"source":["Подберём параметры нашей модели"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"8WzoRJZd25qF"},"source":["* Переберите по сетке от `1` до `10` параметр числа соседей\n","\n","* Также вы попробуйте использоввать различные метрики: `['manhattan', 'euclidean']`\n","\n","* Попробуйте использовать различные стратегии вычисления весов: `[‘uniform’, ‘distance’]`"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"4lMSy-6f25qG","scrolled":true,"colab":{"base_uri":"https://localhost:8080/","height":230},"outputId":"b7d34f6d-3490-41ba-e5da-cbe9df8a1248","executionInfo":{"status":"ok","timestamp":1584842136912,"user_tz":-180,"elapsed":29962,"user":{"displayName":"Михаил Соболев","photoUrl":"","userId":"12877021176396650084"}}},"source":["from sklearn.model_selection import GridSearchCV\n","params = {\n","    'n_neighbors': np.arange(1,10),\n","    'metric': ['manhattan', 'euclidean'],\n","    'weights': ['uniform', 'distance']\n","}\n","\n","clf_grid = GridSearchCV(neig, params, cv=5, scoring='accuracy', n_jobs=-1)\n","clf_grid.fit(feature_matrix, labels)"],"execution_count":33,"outputs":[{"output_type":"execute_result","data":{"text/plain":["GridSearchCV(cv=5, error_score=nan,\n","             estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30,\n","                                            metric='minkowski',\n","                                            metric_params=None, n_jobs=None,\n","                                            n_neighbors=7, p=2,\n","                                            weights='uniform'),\n","             iid='deprecated', n_jobs=-1,\n","             param_grid={'metric': ['manhattan', 'euclidean'],\n","                         'n_neighbors': array([1, 2, 3, 4, 5, 6, 7, 8, 9]),\n","                         'weights': ['uniform', 'distance']},\n","             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n","             scoring='accuracy', verbose=0)"]},"metadata":{"tags":[]},"execution_count":33}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"SO7E6G8jKxZp"},"source":["Выведем лучшие параметры"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"md48pHrMKxZq","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"7bf74ab8-35df-4a92-f167-f917049d6a9f","executionInfo":{"status":"ok","timestamp":1584842151956,"user_tz":-180,"elapsed":679,"user":{"displayName":"Михаил Соболев","photoUrl":"","userId":"12877021176396650084"}}},"source":["clf_grid.best_params_"],"execution_count":34,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'metric': 'manhattan', 'n_neighbors': 4, 'weights': 'distance'}"]},"metadata":{"tags":[]},"execution_count":34}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"M05n9l8pKxZt"},"source":["### Вопрос 2:\n","* Какую metric следует использовать?"]},{"cell_type":"markdown","metadata":{"id":"RqBI1OZo9UTF","colab_type":"text"},"source":["manhattan"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Pmjx38OoKxZt"},"source":["### Вопрос 3:\n","* Сколько n_neighbors следует использовать?"]},{"cell_type":"markdown","metadata":{"id":"54lXbOKn9b6F","colab_type":"text"},"source":["4"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"eqLeJUP8KxZu"},"source":["### Вопрос 4:\n","* Какой тип weights следует использовать?"]},{"cell_type":"markdown","metadata":{"id":"xOQ2-dhy9fAb","colab_type":"text"},"source":["distance"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"aBmiDbvV25qI"},"source":["Используя найденное оптимальное число соседей, вычислите вероятности принадлежности к классам для тестовой выборки (`.predict_proba`)."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ig_vS8O925qI","colab":{}},"source":["optimal_neig = KNeighborsClassifier(metric='manhattan', n_neighbors = 4, weights = 'distance')\n","neig.fit(train_feature_matrix,train_labels)\n","pred_prob = neig.predict_proba(test_feature_matrix)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"2kkapT38KxZz","colab":{"base_uri":"https://localhost:8080/","height":483},"outputId":"9892fed8-62f5-46d7-8561-39bfadf80967","executionInfo":{"status":"ok","timestamp":1584843190659,"user_tz":-180,"elapsed":693,"user":{"displayName":"Михаил Соболев","photoUrl":"","userId":"12877021176396650084"}}},"source":["import matplotlib.pyplot as plt\n","%matplotlib inline\n","import numpy as np\n","\n","unique, freq = np.unique(test_labels, return_counts=True)\n","freq = list(map(lambda x: x / len(test_labels),freq))\n","\n","pred_freq = pred_prob.mean(axis=0)\n","plt.figure(figsize=(10, 8))\n","plt.bar(range(1, 8), pred_freq, width=0.4, align=\"edge\", label='prediction')\n","plt.bar(range(1, 8), freq, width=-0.4, align=\"edge\", label='real')\n","plt.ylim(0, 0.54)\n","plt.legend()\n","plt.show()"],"execution_count":38,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAlMAAAHSCAYAAADIRU4IAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n","text/plain":["<Figure size 720x576 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"cGKGC8t7BWLR","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"9b666ba1-e79e-4f22-d7ff-ca49541a3e7e","executionInfo":{"status":"ok","timestamp":1584843498574,"user_tz":-180,"elapsed":778,"user":{"displayName":"Михаил Соболев","photoUrl":"","userId":"12877021176396650084"}}},"source":["round(pred_freq[2],2)"],"execution_count":43,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.05"]},"metadata":{"tags":[]},"execution_count":43}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"gp4uDyLmKxZ3"},"source":["### Вопрос 5:\n","* Какая прогнозируемая вероятность pred_freq класса под номером 3(до 2 знаков после запятой)?"]},{"cell_type":"markdown","metadata":{"id":"WFPqEREcCLSE","colab_type":"text"},"source":["0.05"]}]}